{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "#from pathlib import Pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with valid values\n",
    "ENDPOINT = \"https://0217-1.cognitiveservices.azure.com/\"\n",
    "training_key = \"f78fb297caf64e1db1b532723952db92\"\n",
    "prediction_key = \"bc05678fd32e4271b396b4938b9315af\"\n",
    "prediction_resource_id = \"/subscriptions/8f4b15f6-5895-4afe-93e2-c87116a788a7/resourceGroups/0217test/providers/Microsoft.CognitiveServices/accounts/02171-Prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n"
     ]
    }
   ],
   "source": [
    "publish_iteration_name = \"detectModel\"\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"My Detection Project\", domain_id=obj_detection_domain.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two tags in the new project\n",
    "black_tag = trainer.create_tag(project.id, \"black\")\n",
    "white_tag = trainer.create_tag(project.id, \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "black_image_regions_pre= {\n",
    "    \"000125\":[131, 394, 375, 624],\n",
    "    \"000126\":[110, 0, 443, 322],\n",
    "    \"000127\":[134, 69, 369, 311],\n",
    "    \"000128\":[60, 149, 364, 503],\n",
    "    \"000129\":[0, 0, 467, 400],\n",
    "    \"000130\":[2, 86, 467, 503],\n",
    "    \"000131\": [75, 184, 410, 476],\n",
    "    \"000132\":[0, 0, 434, 453], \n",
    "    \"000133\":[347, 190, 704, 554],\n",
    "    \"000134\":[127, 262, 656, 741],\n",
    "    \"000741\": [1, 1, 467, 620], \n",
    "    \"000742\": [199, 381, 403, 852], \n",
    "    \"000743\": [243, 389, 406, 863], \n",
    "    \"000744\": [148, 15, 329, 611], \n",
    "    \"000745\": [197, 388, 383, 870]\n",
    "}\n",
    "\n",
    "\n",
    "black_image_regions= {\n",
    "    \"000125\":[ 0.145833328, 0.3509314, 0.5894608, 0.238562092 ],\n",
    "    \"000126\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000127\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000128\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000129\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000130\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000131\":  [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000132\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000133\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000134\": [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000741\":  [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000742\":  [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000743\":  [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000744\":  [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ],\n",
    "    \"000745\":  [ 0.294117659, 0.216944471, 0.534313738, 0.5980392 ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(type(black_image_regions_pre.values()))\n",
    "\n",
    "\n",
    "# white_image_regions = {\n",
    "#     \"000235\":  [ 0.2365196, 0.128709182, 0.5845588, 0.71405226 ],\n",
    "#     \"000236\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000237\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ], \n",
    "#     \"000238\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000239\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000240\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000241\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000242\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000243\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000244\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000245\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ], \n",
    "#     \"000246\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ], \n",
    "#     \"000247\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ],\n",
    "#     \"000248\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ], \n",
    "#     \"000249\":[ 0.234068632, 0.445702642, 0.6127451, 0.344771236 ]\n",
    "    \n",
    "    \n",
    "# }\n",
    "\n",
    "\n",
    "white_image_regions_pre = {\n",
    "    \"000235\": [2, 0, 466, 625], \n",
    "    \"000236\":[2, 1, 467, 348],\n",
    "    \"000237\":[0, 4, 466, 625], \n",
    "    \"000238\":[2, 6, 467, 626], \n",
    "    \"000239\":[2, 81, 467, 626],\n",
    "    \"000240\":[0, 4, 466, 665], \n",
    "    \"000241\":[334, 129, 491, 375],\n",
    "    \"000242\":[258, 424, 635, 818], \n",
    "    \"000243\":[273, 325, 560, 637],\n",
    "    \"000244\":[259, 82, 418, 403],\n",
    "    \"000245\":[243, 339, 492, 690], \n",
    "    \"000246\":[279, 358, 442, 679], \n",
    "    \"000247\":[283, 364, 478, 680],\n",
    "    \"000248\":[344, 331, 531, 636], \n",
    "    \"000249\":[319, 326, 548, 650]\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 466, 625]\n",
      "[2, 1, 467, 348]\n",
      "[0, 4, 466, 625]\n",
      "[2, 6, 467, 626]\n",
      "[2, 81, 467, 626]\n",
      "[0, 4, 466, 665]\n",
      "[334, 129, 491, 375]\n",
      "[258, 424, 635, 818]\n",
      "[273, 325, 560, 637]\n",
      "[259, 82, 418, 403]\n",
      "[243, 339, 492, 690]\n",
      "[279, 358, 442, 679]\n",
      "[283, 364, 478, 680]\n",
      "[344, 331, 531, 636]\n",
      "[319, 326, 548, 650]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#建一個w_json的資料夾 裡面放圖片跟json檔\n",
    "json_p = 'C:/Users/JIALI/Desktop/w_json/'\n",
    "jList = os.listdir(json_p)\n",
    "white_image_regions={} #這是一個dic的資料型態\n",
    "        \n",
    "for file in jList:\n",
    "    \n",
    "    if file.endswith(\".jpg\"):\n",
    "        img = Image.open( os.path.join(json_p,file))\n",
    "        imgSize = img.size  #大小/尺寸\n",
    "        pw = img.width       #图片的宽\n",
    "        ph = img.height      #图片的高\n",
    "        pf = img.format      #图像格式\n",
    "      #  print(imgSize)\n",
    "        #print(pw, ph, pf)\n",
    "    \n",
    "# Region Left(rl) = X1 / Image Width\n",
    "# Region Top(rt) = Y1 / Image Height\n",
    "# Region Width(rw) = (X2 — X1) / image Width\n",
    "# Region Height(rh)= (Y2 — Y1) / image Height\n",
    "    \n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(json_p,file) , 'r') as reader:\n",
    "            jf = json.loads(reader.read())\n",
    "        if jf['item1']['category_id']==2:#如果種類是上衣\n",
    "            print(jf['item1']['bounding_box'])\n",
    "           # print(jf['item1']['bounding_box'][0])\n",
    "            rl=jf['item1']['bounding_box'][0]/pw\n",
    "            rt = jf['item1']['bounding_box'][1]/ph\n",
    "            rw=(jf['item1']['bounding_box'][2]-jf['item1']['bounding_box'][0])/pw\n",
    "            rh=(jf['item1']['bounding_box'][3]-jf['item1']['bounding_box'][1])/ph\n",
    "            #print(Path(file).stem)\n",
    "            white_image_regions[Path(file).stem]=[rl,rt,rw,rh]  #把東西丟到這個dic裡         \n",
    "          #  print (white_image_regions)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# file_path = 'C:/Users/JIALI/Desktop/black/'\n",
    "# allFileList = os.listdir(file_path)\n",
    "        \n",
    "# for file in allFileList:\n",
    "   \n",
    "#     img = Image.open( os.path.join(file_path,file))\n",
    "#     imgSize = img.size  #大小/尺寸\n",
    "#     w = img.width       #图片的宽\n",
    "#     h = img.height      #图片的高\n",
    "#     f = img.format      #图像格式\n",
    "    \n",
    "\n",
    "#     print(imgSize)\n",
    "#     print(w, h, f)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding images...\n"
     ]
    }
   ],
   "source": [
    "# Update this with the path to where you downloaded the images.\n",
    "base_image_location = \"C:/Users/JIALI/Desktop/\"\n",
    "\n",
    "# Go through the data table above and create the images\n",
    "print (\"Adding images...\")\n",
    "tagged_images_with_regions = []\n",
    "\n",
    "for file_name in black_image_regions.keys():\n",
    "    x,y,w,h = black_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=black_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "\n",
    "    with open(base_image_location + \"black/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "for file_name in white_image_regions.keys():\n",
    "    x,y,w,h = white_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=white_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "\n",
    "    with open(base_image_location + \"white/\" + file_name + \".jpg\", mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=tagged_images_with_regions))\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Completed\n"
     ]
    }
   ],
   "source": [
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "CustomVisionErrorException",
     "evalue": "Invalid publish target. A valid publish target should look like: /subscriptions/{subscription id}/resourceGroups/{resource group name}/providers/Microsoft.CognitiveServices/accounts/{prediction resource name}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f168acdc7cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The iteration is now trained. Publish it to the project endpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublish_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpublish_iteration_name\u001b[0m \u001b[1;33m,\u001b[0m  \u001b[0mprediction_resource_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\training\\operations\\_custom_vision_training_client_operations.py\u001b[0m in \u001b[0;36mpublish_iteration\u001b[1;34m(self, project_id, iteration_id, publish_name, prediction_id, overwrite, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCustomVisionErrorException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2524\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCustomVisionErrorException\u001b[0m: Invalid publish target. A valid publish target should look like: /subscriptions/{subscription id}/resourceGroups/{resource group name}/providers/Microsoft.CognitiveServices/accounts/{prediction resource name}"
     ]
    }
   ],
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "#trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "trainer.publish_iteration(project.id, iteration.id,publish_iteration_name ,  prediction_resource_id)\n",
    "\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "# Open the sample image and get back the prediction results.\n",
    "with open(base_image_location + \"test/000024.jpg\", mode=\"rb\") as test_data:\n",
    "    results = predictor.detect_image(project.id, \"iteration-1\", test_data)\n",
    "\n",
    "# Display the results.    \n",
    "for prediction in results.predictions:\n",
    "    print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
